{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef3777f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9438d",
   "metadata": {},
   "source": [
    "## Part 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290705d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903a4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    return np.load(path).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40539943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(0.49, 0.248),\n",
    "                                transforms.RandomAffine(degrees=(-5, 5),\n",
    "                                                        translate=(0, 0.05),\n",
    "                                                        scale=(0.9, 1.1)),\n",
    "                                transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(0.49, 0.248)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde55e11",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Data/Pneumonia/Processed/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDatasetFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/Pneumonia/Processed/train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnpy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mDatasetFolder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Pneumonia/Processed/val/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m                                                  loader\u001b[38;5;241m=\u001b[39mload_file,\n\u001b[0;32m      7\u001b[0m                                                  extensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                                  transform\u001b[38;5;241m=\u001b[39mval_transforms)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m         root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m         is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m(DatasetFolder, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[0;32m    144\u001b[0m                                         target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 145\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchvision\\datasets\\folder.py:221\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchvision\\datasets\\folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Data/Pneumonia/Processed/train/'"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.DatasetFolder('Data/Pneumonia/Processed/train/',\n",
    "                                                   loader=load_file,\n",
    "                                                   extensions='npy',\n",
    "                                                   transform=train_transforms)\n",
    "val_dataset = torchvision.datasets.DatasetFolder('Data/Pneumonia/Processed/val/',\n",
    "                                                 loader=load_file,\n",
    "                                                 extensions='npy',\n",
    "                                                 transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80577d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      5\u001b[0m     random_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m24000\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     x_ray, label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m[random_index]\n\u001b[0;32m      8\u001b[0m     axis[i][j]\u001b[38;5;241m.\u001b[39mimshow(x_ray[\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m     axis[i][j]\u001b[38;5;241m.\u001b[39mset_title(label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis = plt.subplots(2, 2, figsize=(9, 9))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        random_index = np.random.randint(0, 24000)\n",
    "        \n",
    "        x_ray, label = train_dataset[random_index]\n",
    "        axis[i][j].imshow(x_ray[0], cmap='bone')\n",
    "        axis[i][j].set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d156ee41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m      2\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m----> 4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\u001b[43mtrain_dataset\u001b[49m,\n\u001b[0;32m      5\u001b[0m                                            batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      6\u001b[0m                                            num_workers\u001b[38;5;241m=\u001b[39mnum_workers,\n\u001b[0;32m      7\u001b[0m                                            shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(val_dataset,\n\u001b[0;32m     10\u001b[0m                                          batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     11\u001b[0m                                          num_workers\u001b[38;5;241m=\u001b[39mnum_workers,\n\u001b[0;32m     12\u001b[0m                                          shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad4e0ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mtargets, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(train_dataset.targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363387e",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50def06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b7e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = torchvision.models.resnet18()\n",
    "        \n",
    "        # adapt model\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = torch.nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3]))\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "    \n",
    "    \n",
    "    def forward(self, data):\n",
    "        pred = self.model(data)\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "    # define training_step, otherwise pl will throw an error\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.float()\n",
    "        pred = self(x_ray)[:, 0]\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log('Train loss', loss)\n",
    "        self.log('Step Train ACC', self.train_acc(torch.sigmoid(pred), label.int()))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log('Train ACC', self.train_acc.compute())\n",
    "    \n",
    "    \n",
    "    # define validation_step, otherwise pl will throw an error\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.float()\n",
    "        pred = self(x_ray)[:, 0]\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log('Val loss', loss)\n",
    "        self.log('Step Val ACC', self.val_acc(torch.sigmoid(pred), label.int()))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log('Val ACC', self.val_acc.compute())\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289662dd",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb2bbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PneumoniaModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e988e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='Val ACC',\n",
    "                                      save_top_k=10,\n",
    "                                      mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3cf7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = 1\n",
    "trainer = pl.Trainer(gpus=gpus,\n",
    "                     logger=TensorBoardLogger(save_dir='Data/Pneumonia/logs'),\n",
    "                     log_every_n_steps=1,\n",
    "                     callbacks=checkpoint_callback,\n",
    "                     max_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5967e995",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, \u001b[43mtrain_loader\u001b[49m, val_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677978a9",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9679219a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PneumoniaModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       "  (train_acc): Accuracy()\n",
       "  (val_acc): Accuracy()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = PneumoniaModel.load_from_checkpoint('../04-Pneumonia-Classification/weights/weights_3.ckpt')\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16ad704f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# no neccessary gardinets --> raw prediction\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, label \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mval_dataset\u001b[49m):\n\u001b[0;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      8\u001b[0m         pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(model(data)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "# no neccessary gardinets --> raw prediction\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(val_dataset):\n",
    "        data = data.to(device).float().unsqueeze(0)\n",
    "        pred = torch.sigmoid(model(data)[0].cpu())\n",
    "        \n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n",
    "\n",
    "preds = torch.tensor(preds)\n",
    "labels = torch.tensor(labels).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cb38c33",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'is_floating_point'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mtorchmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m precision \u001b[38;5;241m=\u001b[39m torchmetrics\u001b[38;5;241m.\u001b[39mPrecision()(preds, labels)\n\u001b[0;32m      3\u001b[0m recall \u001b[38;5;241m=\u001b[39m torchmetrics\u001b[38;5;241m.\u001b[39mRecall()(preds, labels)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchmetrics\\metric.py:192\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TorchMetricsUserError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Metric shouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be synced when performing ``update``. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHINT: Did you forget to call ``unsync`` ?.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_step:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_sync_on_step\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchmetrics\\metric.py:250\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchmetrics\\classification\\accuracy.py:226\u001b[0m, in \u001b[0;36mAccuracy.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"Update state with predictions and targets. See\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m:ref:`references/modules:input types` for more information on input\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03mtypes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    target: Ground truth labels\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\" returns the mode of the data (binary, multi label, multi class, multi-dim multi class) \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[43m_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulticlass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchmetrics\\functional\\classification\\accuracy.py:58\u001b[0m, in \u001b[0;36m_mode\u001b[1;34m(preds, target, threshold, top_k, num_classes, multiclass)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mode\u001b[39m(\n\u001b[0;32m     30\u001b[0m     preds: Tensor,\n\u001b[0;32m     31\u001b[0m     target: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     multiclass: Optional[\u001b[38;5;28mbool\u001b[39m],\n\u001b[0;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataType:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124;03m\"\"\"Finds the mode of the input tensors.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m        <DataType.MULTICLASS: 'multi-class'>\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[43m_check_classification_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulticlass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulticlass\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mode\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:251\u001b[0m, in \u001b[0;36m_check_classification_inputs\u001b[1;34m(preds, target, threshold, num_classes, multiclass, top_k)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m\"\"\"Performs error checking on inputs for classification.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mThis ensures that preds and target take one of the shape/type combinations that are\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m        'multi-dim multi-class'\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Basic validation (that does not need case/type information)\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43m_basic_input_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulticlass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Check that shape/types fall into one of the cases\u001b[39;00m\n\u001b[0;32m    254\u001b[0m case, implied_classes \u001b[38;5;241m=\u001b[39m _check_shape_and_type_consistency(preds, target)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch39\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:32\u001b[0m, in \u001b[0;36m_basic_input_validation\u001b[1;34m(preds, target, threshold, multiclass)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_basic_input_validation\u001b[39m(preds: Tensor, target: Tensor, threshold: \u001b[38;5;28mfloat\u001b[39m, multiclass: Optional[\u001b[38;5;28mbool\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform basic validation of inputs that does not require deducing any information of the type of inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m():\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `target` has to be an integer tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'is_floating_point'"
     ]
    }
   ],
   "source": [
    "acc = torchmetrics.Accuracy()(preds, labels)\n",
    "precision = torchmetrics.Precision()(preds, labels)\n",
    "recall = torchmetrics.Recall()(preds, labels)\n",
    "cm = torchmetrics.ConfusionMatrix(num_classes=2)(preds, labels)\n",
    "\n",
    "print(f'Val Accuracy {acc}')\n",
    "print(f'Val Precision {precision}')\n",
    "print(f'Val Recall {recall}')\n",
    "print(f'Confusion Matrix {cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f8a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
