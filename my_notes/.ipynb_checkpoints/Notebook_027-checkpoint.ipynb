{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65954484",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02716c7",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torchio as tio\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from model_3d import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ec2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_img_to_label_path(path):\n",
    "    \"\"\"\n",
    "    Replace data with mask to get the masks\n",
    "    \"\"\"\n",
    "    parts = list(path.parts)\n",
    "    parts[parts.index(\"imagesTr\")] = \"labelsTr\"\n",
    "    return Path(*parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70cb086",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('Data/Atrium/Task03_Liver/imagesTr/')\n",
    "subject_paths = list(path.glob('liver_*'))\n",
    "subjects = []\n",
    "\n",
    "for subject_path in subject_paths:\n",
    "    label_path = change_img_to_label_path(subject_path)\n",
    "    subject = tio.Subject({'CT': tio.ScalarImage(subject_path),\n",
    "                           'Label': tio.LabelMap(label_path)})\n",
    "    subjects.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf73910",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    assert subject['CT'].orientation == ('R', 'A', 'S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = tio.Compose([\n",
    "    tio.CropOrPas((256, 256, 200)),\n",
    "    tio.RescaleIntensity((-1, 1))\n",
    "])\n",
    "\n",
    "augmentation = tio.RandomAffine(scales=(0.9, 1.1), degrees=(-10, 10))\n",
    "\n",
    "val_transform = process\n",
    "train_transform = tio.Compose([process, augmentation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tio.SubjectsDataset(subjects[:105], transform=train_transform)\n",
    "val_dataset = tio.SubjectsDataset(subjects[105:], transform=val_transform)\n",
    "\n",
    "sampler = tio.data.LabelSampler(patch_size=96, label_name='Label',\n",
    "                                label_probabilities={0:0.2, 1:0.3, 2:0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches_queue = tio.Queue(train_dataset, max_length=40, samples_per_volume=5,\n",
    "                                sampler=sampler, num_workers=4)\n",
    "val_patches_queue = tio.Queue(val_dataset, max_length=40, samples_per_volume=5,\n",
    "                              sampler=sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127db740",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_patches_queue, batch_size=2, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_patches_queue, batch_size=2, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904c485",
   "metadata": {},
   "source": [
    "## Part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95249597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmenter(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = UNet()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img = batch['CT']['data']\n",
    "        mask = batch['Label']['data'][:, 0]\n",
    "        mask = mask.long()\n",
    "        \n",
    "        pred = self(img)\n",
    "        loss = self.loss_fn(pred, mask)\n",
    "        \n",
    "        self.log(\"Train Loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img = batch['CT']['data']\n",
    "        mask = batch['Label']['data'][:, 0]\n",
    "        mask = mask.long()\n",
    "        \n",
    "        pred = self(img)\n",
    "        loss = self.loss_fn(pred, mask)\n",
    "        \n",
    "        self.log(\"Val Loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3074ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='Val Loss',\n",
    "    save_top_k=10,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff237142",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1, logger=TensorBoardLogger(save_dir='logs/liver'), \n",
    "                     log_every_n_steps=1, callbacks=checkpoint_callback, max_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4a7ea",
   "metadata": {},
   "source": [
    "## Part 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7be179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from celluloid import Camera\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmenter.load_from_checkpoint('logs/liver/checkpoints/...')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.eval();\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1dc27",
   "metadata": {},
   "source": [
    "### Patch Aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 4\n",
    "imgs = val_dataset[IDX]['CT']['data']\n",
    "mask = val_dataset[IDX]['Label']['data']\n",
    "\n",
    "grid_sampler = tio.inference.GridSampler(val_dataset[IDX], 96, (8, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d76cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = tio.inference.GridAggregator(grid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf53df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_loader = torch.utils.data.DataLoader(grid_sampler, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f64358",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for patches_batch in patch_loader:\n",
    "        input_tensor = patches_batch['CT']['data'].to(device)\n",
    "        locations = patches_batch[tio.LOCATION]\n",
    "        \n",
    "        pred = model(input_tensor)\n",
    "        aggregator.add_batch(pred, locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = aggregator.get_output_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "pred = output_tensor.argmax(0)\n",
    "\n",
    "for i in range(0, output_tensor.shape[-1], 2):\n",
    "    plt.imshow(imgs[0, :, :, i], cmap='bone')\n",
    "    \n",
    "    mask_ = np.ma.masked_where(pred[:, :, i] == 0, pred[:, :, i])\n",
    "    plt.imshow(mask_, alpha=0.5, cmap='autumn')\n",
    "    \n",
    "    camera.snap()\n",
    "    \n",
    "animation = camera.animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab25aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
